{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f89bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests to 4square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ec9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6757d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the token\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f9f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4205b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to ask requests to foursquare API\n",
    "\n",
    "def requests_for_foursquare (query, lat, lon, radius=500, limit=50):\n",
    "\n",
    "    url = f\"https://api.foursquare.com/v3/places/search?query={query}&ll={lat}%2C{lon}&radius={radius}&limit={limit}&sort=DISTANCE\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": token}\n",
    "    \n",
    "    try:\n",
    "        return requests.get(url, headers=headers).json()\n",
    "    except:\n",
    "        print(\"no :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84833508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the results from the requests received from foursquare converting it to a dictionary.\n",
    "    # This is done to later convert it to df and json\n",
    "\n",
    "def extracting_from_one_element (one_venue):\n",
    "\n",
    "    name = one_venue[\"name\"]\n",
    "    distance = one_venue[\"distance\"]\n",
    "    lat = one_venue[\"geocodes\"][\"main\"][\"latitude\"]\n",
    "    lon = one_venue[\"geocodes\"][\"main\"][\"longitude\"]\n",
    "    \n",
    "    small_dict = {\n",
    "    \"name\": name,\n",
    "    \"distance\": distance,\n",
    "    \"location\": [lat,lon]\n",
    "}\n",
    "    return small_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "658ff2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the requests results into dataframes to work with them\n",
    "\n",
    "def transform_request_into_df (res):\n",
    "    list_of_dictionaries = [extracting_from_one_element (element) for element in res[\"results\"]]\n",
    "    return pd.DataFrame(list_of_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9abb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will create a unique dataframe for a particular venue merging the venues resulting for the requests from the 3 neighborhoods.\n",
    "    # e.g.: a dataframe with all the schools within 1km of the company located in Camden, the one in Wesminster and in Kensington\n",
    "    \n",
    "\n",
    "def request_to_df (venue):\n",
    "    \n",
    "    #Defining the variables for the locations based on the selected companies \n",
    "    \n",
    "    playfish_lat = 51.539778\n",
    "    playfish_long = -0.152998\n",
    "\n",
    "    worldtv_lat = 51.500152 \n",
    "    worldtv_long = -0.126236\n",
    "\n",
    "    pikum_lat = 51.499109 \n",
    "    pikum_long = -0.198480\n",
    "    \n",
    "    #Doing the requests using the requests created function\n",
    "\n",
    "    pikum = requests_for_foursquare (venue, pikum_lat, pikum_long, radius=1000, limit=50)\n",
    "    df_pikum = transform_request_into_df (pikum)\n",
    "\n",
    "    worldtv = requests_for_foursquare (venue, worldtv_lat, worldtv_long, radius=1000, limit=50)\n",
    "    df_worldtv = transform_request_into_df (worldtv)\n",
    "\n",
    "    playfish = requests_for_foursquare (venue, playfish_lat, playfish_long, radius=1000, limit=50)\n",
    "    df_playfish = transform_request_into_df (playfish)\n",
    "    \n",
    "    merged_df = pd.concat([df_pikum, df_worldtv, df_playfish]).reset_index(drop=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96624120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the df to json file so we can load it to mongo\n",
    "\n",
    "def df_to_json (df,file_name):\n",
    "    json_file = df.to_json(f'data/{file_name}.json', orient='records')\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8445b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the json files into mongo as collections\n",
    "\n",
    "import pymongo\n",
    "\n",
    "def import_mongo (file_name,collection_name):\n",
    "    client = pymongo.MongoClient(\"localhost:27017\")\n",
    "    db = client[\"London\"]\n",
    "    c = db.get_collection(\"companies\")\n",
    "    venues = pd.read_json(f'data/{file_name}.json').to_dict(orient='records')\n",
    "    c.insert_many(venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application of the funtions to the multiple criteria to get collections for each type of venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a42adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "party = request_to_df ((\"bar\",\"club\"))\n",
    "party_json = df_to_json (party,\"london_party\")\n",
    "import_mongo (\"london_party\",\"london_party\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4abdcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = request_to_df (\"school\")\n",
    "school_json = df_to_json (schools,\"london_schools\")\n",
    "import_mongo (\"london_schools\",\"london_schools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f557060",
   "metadata": {},
   "outputs": [],
   "source": [
    "starbucks = request_to_df (\"starbucks\")\n",
    "starbucks_json = df_to_json (starbucks,\"london_starbucks\")\n",
    "import_mongo (\"london_starbucks\",\"london_starbucks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44b35db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegans = request_to_df (\"vegan restaurant\")\n",
    "party_json = df_to_json (vegans,\"london_vegans\")\n",
    "import_mongo (\"london_vegans\",\"london_vegans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5749c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_saloons = request_to_df (\"dog saloon\")\n",
    "dog_json = df_to_json (dog_saloons,\"london_dogsaloons\")\n",
    "import_mongo = (\"london_dogsaloons\", \"longon_dogsaloons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f78a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('654922b03542e5bc8ead3fa3'), ObjectId('654922b03542e5bc8ead3fa4'), ObjectId('654922b03542e5bc8ead3fa5'), ObjectId('654922b03542e5bc8ead3fa6')], acknowledged=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Doing it sepparate for the Basketball stadium to change the established radio to 10 km\n",
    "\n",
    "pikum = requests_for_foursquare (\"basketball stadium\", pikum_lat, pikum_long, radius=10000, limit=10)\n",
    "df_pikum = transform_request_into_df (pikum)\n",
    "\n",
    "worldtv = requests_for_foursquare (\"basketball stadium\", worldtv_lat, worldtv_long, radius=10000, limit=10)\n",
    "df_worldtv = transform_request_into_df (worldtv)\n",
    "\n",
    "playfish = requests_for_foursquare (\"basketball stadium\", playfish_lat, playfish_long, radius=10000, limit=10)\n",
    "df_playfish = transform_request_into_df (playfish)\n",
    "\n",
    "basketball_stadiums = pd.concat([df_pikum, df_worldtv, df_playfish]).reset_index(drop=True)\n",
    "\n",
    "basketball_json = basketball_stadiums.to_json(f'data/basketball_stadium.json', orient='records')\n",
    "\n",
    "c = db.get_collection(f'london_basketball')\n",
    "venues = pd.read_json(f'data/basketball_stadium.json').to_dict(orient='records')\n",
    "c.insert_many(venues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
